{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIgyxmNn5rz",
        "outputId": "c405cf12-13eb-4374-e7f7-a577d6a0e6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "metadata": {
        "id": "5vYuPxrGntej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLLaupTGlvCl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('city_day.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Lz8-lZnhFe",
        "outputId": "258a5029-55b4-4c38-f34e-2ea0106d7369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                City        Date  PM2.5   PM10     NO    NO2    NOx    NH3  \\\n",
            "0          Ahmedabad  2015-01-01    NaN    NaN   0.92  18.22  17.15    NaN   \n",
            "1          Ahmedabad  2015-01-02    NaN    NaN   0.97  15.69  16.46    NaN   \n",
            "2          Ahmedabad  2015-01-03    NaN    NaN  17.40  19.30  29.70    NaN   \n",
            "3          Ahmedabad  2015-01-04    NaN    NaN   1.70  18.48  17.97    NaN   \n",
            "4          Ahmedabad  2015-01-05    NaN    NaN  22.10  21.42  37.76    NaN   \n",
            "...              ...         ...    ...    ...    ...    ...    ...    ...   \n",
            "29526  Visakhapatnam  2020-06-27  15.02  50.94   7.68  25.06  19.54  12.47   \n",
            "29527  Visakhapatnam  2020-06-28  24.38  74.09   3.42  26.06  16.53  11.99   \n",
            "29528  Visakhapatnam  2020-06-29  22.91  65.73   3.45  29.53  18.33  10.71   \n",
            "29529  Visakhapatnam  2020-06-30  16.64  49.97   4.05  29.26  18.80  10.03   \n",
            "29530  Visakhapatnam  2020-07-01  15.00  66.00   0.40  26.85  14.05   5.20   \n",
            "\n",
            "          CO    SO2      O3  Benzene  Toluene  Xylene   AQI    AQI_Bucket  \n",
            "0       0.92  27.64  133.36     0.00     0.02    0.00   NaN           NaN  \n",
            "1       0.97  24.55   34.06     3.68     5.50    3.77   NaN           NaN  \n",
            "2      17.40  29.07   30.70     6.80    16.40    2.25   NaN           NaN  \n",
            "3       1.70  18.59   36.08     4.43    10.14    1.00   NaN           NaN  \n",
            "4      22.10  39.33   39.31     7.01    18.89    2.78   NaN           NaN  \n",
            "...      ...    ...     ...      ...      ...     ...   ...           ...  \n",
            "29526   0.47   8.55   23.30     2.24    12.07    0.73  41.0          Good  \n",
            "29527   0.52  12.72   30.14     0.74     2.21    0.38  70.0  Satisfactory  \n",
            "29528   0.48   8.42   30.96     0.01     0.01    0.00  68.0  Satisfactory  \n",
            "29529   0.52   9.84   28.30     0.00     0.00    0.00  54.0  Satisfactory  \n",
            "29530   0.59   2.10   17.05      NaN      NaN     NaN  50.0          Good  \n",
            "\n",
            "[29531 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beJAqAf_pIz3",
        "outputId": "03ffa6c1-9763-48ec-f6dd-0b63996e0400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29531 entries, 0 to 29530\n",
            "Data columns (total 16 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   City        29531 non-null  object \n",
            " 1   Date        29531 non-null  object \n",
            " 2   PM2.5       24933 non-null  float64\n",
            " 3   PM10        18391 non-null  float64\n",
            " 4   NO          25949 non-null  float64\n",
            " 5   NO2         25946 non-null  float64\n",
            " 6   NOx         25346 non-null  float64\n",
            " 7   NH3         19203 non-null  float64\n",
            " 8   CO          27472 non-null  float64\n",
            " 9   SO2         25677 non-null  float64\n",
            " 10  O3          25509 non-null  float64\n",
            " 11  Benzene     23908 non-null  float64\n",
            " 12  Toluene     21490 non-null  float64\n",
            " 13  Xylene      11422 non-null  float64\n",
            " 14  AQI         24850 non-null  float64\n",
            " 15  AQI_Bucket  24850 non-null  object \n",
            "dtypes: float64(13), object(3)\n",
            "memory usage: 3.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Count missing values in each column\n",
        "print(\"Missing Values Count:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAlaWGMe1VS5",
        "outputId": "03dbdad6-d738-4300-9573-81a9b18e7913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Count:\n",
            "City              0\n",
            "Date              0\n",
            "PM2.5          4598\n",
            "PM10          11140\n",
            "NO             3582\n",
            "NO2            3585\n",
            "NOx            4185\n",
            "NH3           10328\n",
            "CO             2059\n",
            "SO2            3854\n",
            "O3             4022\n",
            "Benzene        5623\n",
            "Toluene        8041\n",
            "Xylene        18109\n",
            "AQI            4681\n",
            "AQI_Bucket     4681\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop rows where the target variable 'PM2.5' is missing\n",
        "df.dropna(subset=['PM2.5'], inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvAa2VNGCioh",
        "outputId": "d8af9c46-5258-4d49-f421-cd11b665615f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City              0\n",
            "Date              0\n",
            "PM2.5             0\n",
            "PM10           7301\n",
            "NO              351\n",
            "NO2             377\n",
            "NOx            1470\n",
            "NH3            6644\n",
            "CO              370\n",
            "SO2             505\n",
            "O3              752\n",
            "Benzene        3151\n",
            "Toluene        5555\n",
            "Xylene        15273\n",
            "AQI             761\n",
            "AQI_Bucket      761\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Impute missing values for other numerical columns using their median\n",
        "# Get a list of numerical columns (excluding the target and object types)\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_cols.remove('PM2.5')\n",
        "print(numerical_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4xdqL8jDGDO",
        "outputId": "1427a57e-9414-4c63-bd30-153c19ab7327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_cols:\n",
        "    median_val = df[col].median()\n",
        "    df[col].fillna(median_val, inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa9hjtt6EYxP",
        "outputId": "46687eda-7987-461c-c254-72573765e104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City            0\n",
            "Date            0\n",
            "PM2.5           0\n",
            "PM10            0\n",
            "NO              0\n",
            "NO2             0\n",
            "NOx             0\n",
            "NH3             0\n",
            "CO              0\n",
            "SO2             0\n",
            "O3              0\n",
            "Benzene         0\n",
            "Toluene         0\n",
            "Xylene          0\n",
            "AQI             0\n",
            "AQI_Bucket    761\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3052925097.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(median_val, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column from object to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "print(\"\\nData types after converting 'Date' column:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vzhWkL8EogI",
        "outputId": "408502c1-1749-4c61-c2fd-548f40a5352e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data types after converting 'Date' column:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 24933 entries, 27 to 29530\n",
            "Data columns (total 16 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   City        24933 non-null  object        \n",
            " 1   Date        24933 non-null  datetime64[ns]\n",
            " 2   PM2.5       24933 non-null  float64       \n",
            " 3   PM10        24933 non-null  float64       \n",
            " 4   NO          24933 non-null  float64       \n",
            " 5   NO2         24933 non-null  float64       \n",
            " 6   NOx         24933 non-null  float64       \n",
            " 7   NH3         24933 non-null  float64       \n",
            " 8   CO          24933 non-null  float64       \n",
            " 9   SO2         24933 non-null  float64       \n",
            " 10  O3          24933 non-null  float64       \n",
            " 11  Benzene     24933 non-null  float64       \n",
            " 12  Toluene     24933 non-null  float64       \n",
            " 13  Xylene      24933 non-null  float64       \n",
            " 14  AQI         24933 non-null  float64       \n",
            " 15  AQI_Bucket  24172 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(13), object(2)\n",
            "memory usage: 3.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the 'Date' column\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day"
      ],
      "metadata": {
        "id": "dHjoOgTSEt9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['City']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "TEpov_AmuLDl",
        "outputId": "6b569ddf-e214-4316-8b6c-ce523c531540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27           Ahmedabad\n",
              "28           Ahmedabad\n",
              "29           Ahmedabad\n",
              "30           Ahmedabad\n",
              "31           Ahmedabad\n",
              "             ...      \n",
              "29526    Visakhapatnam\n",
              "29527    Visakhapatnam\n",
              "29528    Visakhapatnam\n",
              "29529    Visakhapatnam\n",
              "29530    Visakhapatnam\n",
              "Name: City, Length: 24933, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Ahmedabad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Ahmedabad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Ahmedabad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Ahmedabad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Ahmedabad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29526</th>\n",
              "      <td>Visakhapatnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29527</th>\n",
              "      <td>Visakhapatnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29528</th>\n",
              "      <td>Visakhapatnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29529</th>\n",
              "      <td>Visakhapatnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29530</th>\n",
              "      <td>Visakhapatnam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24933 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode the 'City' column\n",
        "df = pd.get_dummies(df, columns=['City'], drop_first=True)"
      ],
      "metadata": {
        "id": "8fIK91BZFBg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop columns that are not needed or cause data leakage\n",
        "df.drop(['Date', 'AQI', 'AQI_Bucket'], axis=1, inplace=True)\n",
        "\n",
        "print(\"\\nDataFrame after Feature Engineering:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPqiGBt6uC-T",
        "outputId": "a8d7f469-20c4-43bd-b7f1-4a6815979486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Feature Engineering:\n",
            "     PM2.5    PM10     NO    NO2    NOx    NH3     CO    SO2      O3  Benzene  \\\n",
            "27   73.24  95.595   5.72  21.11  25.84  16.53   5.72  36.52   62.42     0.03   \n",
            "28   83.13  95.595   6.93  28.71  33.72  16.53   6.93  49.52   59.76     0.02   \n",
            "29   79.84  95.595  13.85  28.68  41.08  16.53  13.85  48.49   97.07     0.04   \n",
            "30   94.52  95.595  24.39  32.66  52.61  16.53  24.39  67.39  111.33     0.24   \n",
            "31  135.99  95.595  43.48  42.08  84.57  16.53  43.48  75.23  102.70     0.40   \n",
            "\n",
            "    ...  City_Jorapokhar  City_Kochi  City_Kolkata  City_Lucknow  City_Mumbai  \\\n",
            "27  ...            False       False         False         False        False   \n",
            "28  ...            False       False         False         False        False   \n",
            "29  ...            False       False         False         False        False   \n",
            "30  ...            False       False         False         False        False   \n",
            "31  ...            False       False         False         False        False   \n",
            "\n",
            "    City_Patna  City_Shillong  City_Talcher  City_Thiruvananthapuram  \\\n",
            "27       False          False         False                    False   \n",
            "28       False          False         False                    False   \n",
            "29       False          False         False                    False   \n",
            "30       False          False         False                    False   \n",
            "31       False          False         False                    False   \n",
            "\n",
            "    City_Visakhapatnam  \n",
            "27               False  \n",
            "28               False  \n",
            "29               False  \n",
            "30               False  \n",
            "31               False  \n",
            "\n",
            "[5 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your features (X) and target (y)\n",
        "X = df.drop('PM2.5', axis=1)\n",
        "y = df['PM2.5']"
      ],
      "metadata": {
        "id": "8uyCTTs_vJJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the numerical features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform it\n",
        "X_train_scaled = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "qS635l7JFpSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the test data using the SAME scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nTraining data shape: {X_train_scaled.shape}\")\n",
        "print(f\"Testing data shape: {X_test_scaled.shape}\")"
      ],
      "metadata": {
        "id": "kHoisorZ05BA",
        "outputId": "5358aec7-16e7-4f61-9eb3-6817e3fc34c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training data shape: (19946, 39)\n",
            "Testing data shape: (4987, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hVM3DCfwbOA",
        "outputId": "58d3a03f-6acc-41b5-bd55-0a2589e1808c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.72498815 -0.68265466 -0.73996923 ... -0.17776592 -0.2129156\n",
            "  -0.22731347]\n",
            " [-0.20480822  2.65488744  3.67108744 ... -0.17776592 -0.2129156\n",
            "  -0.22731347]\n",
            " [ 0.69935018  1.00378218  1.58090758 ... -0.17776592 -0.2129156\n",
            "  -0.22731347]\n",
            " ...\n",
            " [-0.20480822  2.61007665  2.32249194 ... -0.17776592 -0.2129156\n",
            "  -0.22731347]\n",
            " [-1.00478539 -0.24531859 -0.35179297 ... -0.17776592 -0.2129156\n",
            "  -0.22731347]\n",
            " [-1.05324485 -0.4986719  -0.75224035 ... -0.17776592  4.69669666\n",
            "  -0.22731347]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.linear_model import LinearRegression # Changed from LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score # Imported regression metrics\n",
        "\n",
        "# Train a Linear Regression model\n",
        "# Linear Regression is a simple model with limited hyperparameters for optimization.\n",
        "# To potentially reduce the error rate significantly, consider trying other regression models\n",
        "# like Ridge, Lasso, Elastic Net, Decision Tree Regressor, Random Forest Regressor,\n",
        "# or Gradient Boosting models. You could also explore feature engineering or hyperparameter tuning.\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model using regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False) # Calculate RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Create an evaluation report dictionary for regression\n",
        "evaluation_report = {\n",
        "    \"mean_squared_error\": mse,\n",
        "    \"rmse\": rmse,\n",
        "    \"r2_score\": r2,\n",
        "}\n",
        "\n",
        "# Export the evaluation report to a JSON file\n",
        "with open('linear_regression_evaluation_report.json', 'w') as f:\n",
        "    json.dump(evaluation_report, f, indent=4)\n",
        "\n",
        "print(\"Evaluation report exported to linear_regression_evaluation_report.json\")"
      ],
      "metadata": {
        "id": "LTIo8eaxDF2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3933df8-f7d6-4347-efd7-975257c9f341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation report exported to linear_regression_evaluation_report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluation_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8bLH3-3yN-6",
        "outputId": "6a97cac2-228a-4275-ad08-7fde9cdd7ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean_squared_error': 2108.3971242074217, 'rmse': np.float64(45.91728567987683), 'r2_score': 0.5078555964030003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "\n",
        "# We'll still use these for the final evaluation\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "qfsOIdr4116K"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "JL1th7h42g-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe82851b-8326-4477-8929-cb48afceaf6b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras_tuner) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    \"\"\"\n",
        "    This function builds a Keras model and defines the hyperparameters we want to tune.\n",
        "    'hp' is a special object provided by KerasTuner that allows us to define searchable ranges.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1. Tune the number of units (neurons) in the first hidden layer.\n",
        "    # We'll search for an integer between 32 and 128.\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=128, step=16)\n",
        "\n",
        "    # Add the input layer and first hidden layer\n",
        "    # The input_shape must match the number of features in your data (X_train_scaled.shape[1])\n",
        "    model.add(layers.Dense(units=hp_units, activation='relu', input_shape=[X_train_scaled.shape[1]]))\n",
        "\n",
        "    # Add a second hidden layer for a deeper model\n",
        "    hp_units_2 = hp.Int('units_2', min_value=16, max_value=64, step=16)\n",
        "    model.add(layers.Dense(units=hp_units_2, activation='relu'))\n",
        "\n",
        "    # Add the output layer. It has 1 neuron because we are predicting a single value (PM2.5).\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    # 2. Tune the learning rate for the Adam optimizer.\n",
        "    # We'll try three different values: 0.01, 0.001, or 0.0001.\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='mean_squared_error', # A common loss function for regression\n",
        "                  metrics=['mean_squared_error'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-Oksu3wQ14LL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss', # The metric to minimize\n",
        "    max_trials=10,        # The total number of hyperparameter combinations to test\n",
        "    executions_per_trial=2, # The number of models to train and evaluate for each trial\n",
        "    directory='my_dir',   # A directory to store the results\n",
        "    project_name='pm25_tuning'\n",
        ")\n",
        "\n",
        "# A callback to stop training early if the validation loss stops improving\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Start the search!\n",
        "print(\"Starting hyperparameter search...\")\n",
        "tuner.search(X_train_scaled, y_train,\n",
        "             epochs=50,\n",
        "             validation_split=0.2, # Use 20% of training data for validation\n",
        "             callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Search complete! 🎉\n",
        "The optimal number of units in the first layer is {best_hps.get('units')}.\n",
        "The optimal number of units in the second layer is {best_hps.get('units_2')}.\n",
        "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "tNHaZV6y168Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1619532a-25e7-4f64-9246-9374c023a3bc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 45s]\n",
            "val_loss: 1312.8131713867188\n",
            "\n",
            "Best val_loss So Far: 1237.4491577148438\n",
            "Total elapsed time: 00h 15m 30s\n",
            "\n",
            "Search complete! 🎉\n",
            "The optimal number of units in the first layer is 80.\n",
            "The optimal number of units in the second layer is 32.\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters\n",
        "final_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the final model\n",
        "print(\"\\nTraining the final model with the best hyperparameters...\")\n",
        "history = final_model.fit(X_train_scaled, y_train,\n",
        "                          epochs=100, # Train for more epochs on the final model\n",
        "                          validation_split=0.2,\n",
        "                          callbacks=[stop_early],\n",
        "                          verbose=0) # verbose=0 silences the output for each epoch\n",
        "\n",
        "print(\"✅ Final model trained successfully!\")"
      ],
      "metadata": {
        "id": "fHGobe1N1-qN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e38d91-46fc-41d5-e6b5-8dc65caf01dc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the final model with the best hyperparameters...\n",
            "✅ Final model trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_nn = final_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
        "r2_nn = r2_score(y_test, y_pred_nn)\n",
        "\n",
        "print(f\"\\n--- Final Model Evaluation on Test Data ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_nn:.2f}\")\n",
        "print(f\"R-squared (R²): {r2_nn:.2f}\")\n",
        "\n",
        "# Compare with the previous Linear Regression model\n",
        "print(f\"\\n--- Comparison ---\")\n",
        "print(f\"Simple Linear Regression R²: {r2:.2f}\") # 'r2' is from your previous code\n",
        "print(f\"Fine-Tuned Neural Network R²: {r2_nn:.2f}\")"
      ],
      "metadata": {
        "id": "XEv2hkS32BG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed71407-601d-42f2-e61c-b68ae66263d1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step\n",
            "\n",
            "--- Final Model Evaluation on Test Data ---\n",
            "Mean Squared Error (MSE): 1064.79\n",
            "R-squared (R²): 0.75\n",
            "\n",
            "--- Comparison ---\n",
            "Simple Linear Regression R²: 0.51\n",
            "Fine-Tuned Neural Network R²: 0.75\n"
          ]
        }
      ]
    }
  ]
}
